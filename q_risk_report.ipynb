{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q Risk Report for HTT\n",
        "\n",
        "This notebook generates a comprehensive quantitative risk report using EWMA covariance estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configuration & Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded:\n",
            "  Product: clbr (from column: CLBR)\n",
            "  Front bucket: ['A01', 'A02', 'A03', 'A04']\n",
            "  Mid bucket: ['A05', 'A06', 'A07', 'A08']\n",
            "  Back bucket: ['A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15']\n",
            "  Lambda (front/mid/back): 0.97/0.98/0.99\n",
            "  Loaded 6 positions from delta_summary.csv\n",
            "  Contract-to-node mappings: 15 contracts\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION - Edit these parameters as needed\n",
        "# ============================================================================\n",
        "\n",
        "product = \"clbr\"\n",
        "\n",
        "# Bucket definitions\n",
        "front = [\"A01\", \"A02\", \"A03\", \"A04\"]\n",
        "mid   = [\"A05\", \"A06\", \"A07\", \"A08\"]\n",
        "back  = [\"A09\", \"A10\", \"A11\", \"A12\", \"A13\", \"A14\", \"A15\"]\n",
        "\n",
        "# EWMA decay parameters (lambda)\n",
        "lambda_front = 0.97\n",
        "lambda_mid   = 0.98\n",
        "lambda_back  = 0.99\n",
        "lambda_cross = 0.985  # For cross-bucket correlations (if using Option 2)\n",
        "\n",
        "# EWMA initialization\n",
        "ewma_init_obs = 60  # Use first N observations for sample covariance initialization\n",
        "\n",
        "# Data file path\n",
        "data_file = \"data_.csv\"\n",
        "\n",
        "# Delta summary file path\n",
        "delta_summary_file = \"delta_summary.csv\"\n",
        "\n",
        "# Holidays file path\n",
        "holidays_file = \"holidays.csv\"\n",
        "\n",
        "# Load delta summary\n",
        "delta_summary_df = pd.read_csv(delta_summary_file)\n",
        "\n",
        "# Load holidays and create set for fast lookup\n",
        "holidays_df = pd.read_csv(holidays_file, header=None, names=['date'])\n",
        "holidays_df = holidays_df.dropna()  # Remove empty rows\n",
        "holidays_df['date'] = pd.to_datetime(holidays_df['date'], format='%m/%d/%Y', errors='coerce')\n",
        "holidays_df = holidays_df.dropna()  # Remove any rows that couldn't be parsed\n",
        "holiday_dates = set(holidays_df['date'].dt.date)  # Use .date() for date-only comparison\n",
        "print(f\"  Loaded {len(holiday_dates)} holiday dates from holidays.csv\")\n",
        "\n",
        "# Build complete contract-to-node mapping for all tenors in delta_summary.csv\n",
        "# Map tenors chronologically to A01-A15 (first 15 tenors in the CSV)\n",
        "# The order in delta_summary.csv is: H6, J6, K6, M6, N6, Q6, U6, V6, X6, Z6, F7, G7, H7, J7, K7, ...\n",
        "unique_tenors = delta_summary_df['Tenor'].unique()\n",
        "contract_to_node = {}\n",
        "for idx, tenor in enumerate(unique_tenors[:15]):  # Only map first 15 to A01-A15\n",
        "    node_code = f\"A{idx+1:02d}\"\n",
        "    contract_to_node[tenor] = node_code\n",
        "\n",
        "# Find product column (case-insensitive matching)\n",
        "product_upper = product.upper()\n",
        "available_products = [col for col in delta_summary_df.columns if col.upper() == product_upper]\n",
        "if not available_products:\n",
        "    # Try to find a close match\n",
        "    all_products = [col for col in delta_summary_df.columns if col != 'Tenor']\n",
        "    raise ValueError(f\"Product '{product}' not found in delta_summary.csv. Available products: {all_products}\")\n",
        "product_column = available_products[0]\n",
        "\n",
        "# Build pos_codes dictionary from delta_summary.csv for the selected product\n",
        "pos_codes = {}\n",
        "for _, row in delta_summary_df.iterrows():\n",
        "    tenor = row['Tenor']\n",
        "    position = row[product_column]\n",
        "    # Only include non-zero positions\n",
        "    if abs(position) > 1e-10:  # Use small threshold to handle floating point precision\n",
        "        pos_codes[tenor] = float(position)\n",
        "\n",
        "print(\"Configuration loaded:\")\n",
        "print(f\"  Product: {product} (from column: {product_column})\")\n",
        "print(f\"  Front bucket: {front}\")\n",
        "print(f\"  Mid bucket: {mid}\")\n",
        "print(f\"  Back bucket: {back}\")\n",
        "print(f\"  Lambda (front/mid/back): {lambda_front}/{lambda_mid}/{lambda_back}\")\n",
        "print(f\"  Loaded {len(pos_codes)} positions from delta_summary.csv\")\n",
        "print(f\"  Contract-to-node mappings: {len(contract_to_node)} contracts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load & Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found HTT columns: ['clbr_A01', 'clbr_A02', 'clbr_A03', 'clbr_A04', 'clbr_A05', 'clbr_A06', 'clbr_A07', 'clbr_A08', 'clbr_A09', 'clbr_A10', 'clbr_A11', 'clbr_A12', 'clbr_A13', 'clbr_A14', 'clbr_A15']\n",
            "Date range: 2022-01-03 00:00:00 to 2025-12-25 00:00:00\n",
            "Total observations: 1041\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": []
        }
      ],
      "source": [
        "# Load data\n",
        "df_raw = pd.read_csv(data_file)\n",
        "\n",
        "# Parse date column\n",
        "df_raw['date'] = pd.to_datetime(df_raw['date'])\n",
        "df_raw = df_raw.set_index('date').sort_index()\n",
        "\n",
        "# Extract HTT columns (htt_A01 through htt_A15)\n",
        "htt_cols = [col for col in df_raw.columns if col.startswith(f'{product}_A') and '/' not in col]\n",
        "htt_cols = sorted(htt_cols, key=lambda x: int(x.split('_A')[1]))\n",
        "\n",
        "print(f\"Found HTT columns: {htt_cols}\")\n",
        "print(f\"Date range: {df_raw.index.min()} to {df_raw.index.max()}\")\n",
        "print(f\"Total observations: {len(df_raw)}\")\n",
        "\n",
        "# Extract price data\n",
        "df_prices = df_raw[htt_cols].copy()\n",
        "\n",
        "# Compute daily changes (Î”price_t, not % returns)\n",
        "df_returns = df_prices.diff().dropna()\n",
        "\n",
        "# Drop any rows with NA after differencing\n",
        "df_returns = df_returns.dropna()\n",
        "\n",
        "# Filter out holiday dates\n",
        "initial_count = len(df_returns)\n",
        "# Convert index dates to a list and check membership\n",
        "is_holiday = [date.date() in holiday_dates for date in df_returns.index]\n",
        "df_returns = df_returns[~pd.Series(is_holiday, index=df_returns.index)]\n",
        "removed_count = initial_count - len(df_returns)\n",
        "\n",
        "print(f\"\\nReturns data shape: {df_returns.shape}\")\n",
        "print(f\"Removed {removed_count} holiday dates from returns data (out of {initial_count} total)\")\n",
        "print(f\"First few returns:\")\n",
        "print(df_returns.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clbr_A01</th>\n",
              "      <th>clbr_A02</th>\n",
              "      <th>clbr_A03</th>\n",
              "      <th>clbr_A04</th>\n",
              "      <th>clbr_A05</th>\n",
              "      <th>clbr_A06</th>\n",
              "      <th>clbr_A07</th>\n",
              "      <th>clbr_A08</th>\n",
              "      <th>clbr_A09</th>\n",
              "      <th>clbr_A10</th>\n",
              "      <th>clbr_A11</th>\n",
              "      <th>clbr_A12</th>\n",
              "      <th>clbr_A13</th>\n",
              "      <th>clbr_A14</th>\n",
              "      <th>clbr_A15</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-10-17</th>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-6.000000e-02</td>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-7.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-20</th>\n",
              "      <td>1.500000e-01</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-21</th>\n",
              "      <td>-9.000000e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>9.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-22</th>\n",
              "      <td>1.700000e-01</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-7.993606e-15</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-23</th>\n",
              "      <td>-2.200000e-01</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.22</td>\n",
              "      <td>-2.300000e-01</td>\n",
              "      <td>-2.100000e-01</td>\n",
              "      <td>-2.000000e-01</td>\n",
              "      <td>-1.800000e-01</td>\n",
              "      <td>-1.800000e-01</td>\n",
              "      <td>-1.800000e-01</td>\n",
              "      <td>-1.800000e-01</td>\n",
              "      <td>-1.700000e-01</td>\n",
              "      <td>-1.600000e-01</td>\n",
              "      <td>-1.600000e-01</td>\n",
              "      <td>-1.600000e-01</td>\n",
              "      <td>-1.600000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-24</th>\n",
              "      <td>-1.100000e-01</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-27</th>\n",
              "      <td>1.200000e-01</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.100000e-01</td>\n",
              "      <td>9.000000e-02</td>\n",
              "      <td>9.000000e-02</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-28</th>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-29</th>\n",
              "      <td>-1.100000e-01</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>-6.661338e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.661338e-15</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-30</th>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-10-31</th>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.05</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-03</th>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-04</th>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-7.993606e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-05</th>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-06</th>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>9.000000e-02</td>\n",
              "      <td>9.000000e-02</td>\n",
              "      <td>1.100000e-01</td>\n",
              "      <td>1.200000e-01</td>\n",
              "      <td>1.300000e-01</td>\n",
              "      <td>1.400000e-01</td>\n",
              "      <td>1.300000e-01</td>\n",
              "      <td>1.300000e-01</td>\n",
              "      <td>1.300000e-01</td>\n",
              "      <td>1.300000e-01</td>\n",
              "      <td>1.300000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-07</th>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-7.105427e-15</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-10</th>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-11</th>\n",
              "      <td>-1.400000e-01</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-12</th>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-7.105427e-15</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>7.105427e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-13</th>\n",
              "      <td>-1.500000e-01</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-8.000000e-02</td>\n",
              "      <td>-9.000000e-02</td>\n",
              "      <td>-8.000000e-02</td>\n",
              "      <td>-8.000000e-02</td>\n",
              "      <td>-6.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-14</th>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-17</th>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-18</th>\n",
              "      <td>1.200000e-01</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.04</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-19</th>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-20</th>\n",
              "      <td>-1.200000e-01</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>6.661338e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-6.661338e-15</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-21</th>\n",
              "      <td>-1.200000e-01</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-7.549517e-15</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-24</th>\n",
              "      <td>3.700000e-01</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.14</td>\n",
              "      <td>9.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-25</th>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.07</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-26</th>\n",
              "      <td>-6.000000e-02</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-6.661338e-15</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-27</th>\n",
              "      <td>-3.300000e-01</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>-2.900000e-01</td>\n",
              "      <td>-2.900000e-01</td>\n",
              "      <td>-2.800000e-01</td>\n",
              "      <td>-2.900000e-01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "      <td>-3.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-11-28</th>\n",
              "      <td>3.600000e-01</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.35</td>\n",
              "      <td>3.500000e-01</td>\n",
              "      <td>3.500000e-01</td>\n",
              "      <td>3.600000e-01</td>\n",
              "      <td>3.500000e-01</td>\n",
              "      <td>3.500000e-01</td>\n",
              "      <td>3.400000e-01</td>\n",
              "      <td>3.300000e-01</td>\n",
              "      <td>3.300000e-01</td>\n",
              "      <td>3.300000e-01</td>\n",
              "      <td>3.300000e-01</td>\n",
              "      <td>3.300000e-01</td>\n",
              "      <td>3.300000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-01</th>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-02</th>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-03</th>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-04</th>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-05</th>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-08</th>\n",
              "      <td>1.100000e-01</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>8.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-09</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-10</th>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-11</th>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-7.000000e-02</td>\n",
              "      <td>-6.000000e-02</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-12</th>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-4.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-7.105427e-15</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-7.105427e-15</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-15</th>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-16</th>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.13</td>\n",
              "      <td>1.200000e-01</td>\n",
              "      <td>1.200000e-01</td>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>6.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-17</th>\n",
              "      <td>-8.000000e-02</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-18</th>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>4.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "      <td>2.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-19</th>\n",
              "      <td>-1.300000e-01</td>\n",
              "      <td>-0.05</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>-7.105427e-15</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-22</th>\n",
              "      <td>2.100000e-01</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.08</td>\n",
              "      <td>8.000000e-02</td>\n",
              "      <td>5.000000e-02</td>\n",
              "      <td>3.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-5.000000e-02</td>\n",
              "      <td>-3.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-23</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-2.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>7.105427e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-24</th>\n",
              "      <td>7.000000e-02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-7.549517e-15</td>\n",
              "      <td>-6.661338e-15</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "      <td>-1.000000e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-12-25</th>\n",
              "      <td>6.180000e+01</td>\n",
              "      <td>61.50</td>\n",
              "      <td>61.37</td>\n",
              "      <td>6.132000e+01</td>\n",
              "      <td>6.130000e+01</td>\n",
              "      <td>6.128000e+01</td>\n",
              "      <td>6.125000e+01</td>\n",
              "      <td>6.124000e+01</td>\n",
              "      <td>6.125000e+01</td>\n",
              "      <td>6.127000e+01</td>\n",
              "      <td>6.127000e+01</td>\n",
              "      <td>6.127000e+01</td>\n",
              "      <td>6.127000e+01</td>\n",
              "      <td>6.127000e+01</td>\n",
              "      <td>6.127000e+01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                clbr_A01  clbr_A02  clbr_A03      clbr_A04      clbr_A05  \\\n",
              "date                                                                       \n",
              "2025-10-17 -7.000000e-02     -0.04     -0.03 -4.000000e-02 -3.000000e-02   \n",
              "2025-10-20  1.500000e-01      0.09      0.05  6.000000e-02  5.000000e-02   \n",
              "2025-10-21 -9.000000e-02      0.02      0.05  5.000000e-02  7.000000e-02   \n",
              "2025-10-22  1.700000e-01      0.06      0.05  3.000000e-02  0.000000e+00   \n",
              "2025-10-23 -2.200000e-01     -0.22     -0.22 -2.300000e-01 -2.100000e-01   \n",
              "2025-10-24 -1.100000e-01     -0.03      0.02  5.000000e-02  5.000000e-02   \n",
              "2025-10-27  1.200000e-01      0.12      0.12  1.100000e-01  9.000000e-02   \n",
              "2025-10-28  7.000000e-02      0.04     -0.01 -2.000000e-02 -1.000000e-02   \n",
              "2025-10-29 -1.100000e-01     -0.05     -0.02 -2.000000e-02 -1.000000e-02   \n",
              "2025-10-30 -1.000000e-02     -0.03     -0.03 -2.000000e-02  0.000000e+00   \n",
              "2025-10-31  7.105427e-15      0.04      0.05  7.000000e-02  6.000000e-02   \n",
              "2025-11-03  3.000000e-02     -0.02     -0.04 -4.000000e-02 -3.000000e-02   \n",
              "2025-11-04  1.000000e-02     -0.02     -0.04 -3.000000e-02 -1.000000e-02   \n",
              "2025-11-05  3.000000e-02      0.01      0.01  1.000000e-02  0.000000e+00   \n",
              "2025-11-06  2.000000e-02      0.04      0.06  6.000000e-02  9.000000e-02   \n",
              "2025-11-07  7.000000e-02      0.01     -0.01  0.000000e+00 -1.000000e-02   \n",
              "2025-11-10 -2.000000e-02     -0.01     -0.02 -3.000000e-02 -3.000000e-02   \n",
              "2025-11-11 -1.400000e-01     -0.07     -0.04 -4.000000e-02 -4.000000e-02   \n",
              "2025-11-12 -5.000000e-02     -0.03     -0.01  1.000000e-02  2.000000e-02   \n",
              "2025-11-13 -1.500000e-01     -0.09     -0.08 -8.000000e-02 -9.000000e-02   \n",
              "2025-11-14 -7.000000e-02     -0.02     -0.02 -1.000000e-02 -1.000000e-02   \n",
              "2025-11-17  1.000000e-01      0.07      0.06  4.000000e-02  3.000000e-02   \n",
              "2025-11-18  1.200000e-01      0.07      0.04  3.000000e-02  1.000000e-02   \n",
              "2025-11-19 -4.000000e-02     -0.03     -0.02 -4.000000e-02 -2.000000e-02   \n",
              "2025-11-20 -1.200000e-01     -0.08     -0.04  6.661338e-15  0.000000e+00   \n",
              "2025-11-21 -1.200000e-01     -0.02     -0.01 -1.000000e-02 -2.000000e-02   \n",
              "2025-11-24  3.700000e-01      0.18      0.14  9.000000e-02  6.000000e-02   \n",
              "2025-11-25  7.000000e-02      0.08      0.07  7.000000e-02  6.000000e-02   \n",
              "2025-11-26 -6.000000e-02     -0.04     -0.03 -2.000000e-02 -6.661338e-15   \n",
              "2025-11-27 -3.300000e-01     -0.32     -0.30 -2.900000e-01 -2.900000e-01   \n",
              "2025-11-28  3.600000e-01      0.35      0.35  3.500000e-01  3.500000e-01   \n",
              "2025-12-01 -1.000000e-02     -0.03     -0.02 -2.000000e-02 -1.000000e-02   \n",
              "2025-12-02  3.000000e-02      0.04      0.02  2.000000e-02  2.000000e-02   \n",
              "2025-12-03  6.000000e-02      0.04      0.01 -1.000000e-02 -2.000000e-02   \n",
              "2025-12-04  6.000000e-02      0.03      0.03  5.000000e-02  4.000000e-02   \n",
              "2025-12-05 -2.000000e-02     -0.03     -0.03 -3.000000e-02 -2.000000e-02   \n",
              "2025-12-08  1.100000e-01      0.11      0.11  8.000000e-02  7.000000e-02   \n",
              "2025-12-09  0.000000e+00      0.03      0.02  3.000000e-02  3.000000e-02   \n",
              "2025-12-10 -5.000000e-02     -0.02      0.01  0.000000e+00  7.105427e-15   \n",
              "2025-12-11  8.000000e-02      0.00     -0.03 -5.000000e-02 -7.000000e-02   \n",
              "2025-12-12 -5.000000e-02     -0.05     -0.06 -4.000000e-02 -2.000000e-02   \n",
              "2025-12-15 -1.000000e-02      0.02      0.03  3.000000e-02  3.000000e-02   \n",
              "2025-12-16  1.000000e-01      0.12      0.13  1.200000e-01  1.200000e-01   \n",
              "2025-12-17 -8.000000e-02     -0.07     -0.04 -2.000000e-02 -2.000000e-02   \n",
              "2025-12-18  5.000000e-02      0.05      0.02  2.000000e-02  3.000000e-02   \n",
              "2025-12-19 -1.300000e-01     -0.05     -0.01  0.000000e+00  1.000000e-02   \n",
              "2025-12-22  2.100000e-01      0.12      0.08  8.000000e-02  5.000000e-02   \n",
              "2025-12-23  0.000000e+00      0.00     -0.01 -2.000000e-02 -2.000000e-02   \n",
              "2025-12-24  7.000000e-02      0.05      0.02  1.000000e-02  1.000000e-02   \n",
              "2025-12-25  6.180000e+01     61.50     61.37  6.132000e+01  6.130000e+01   \n",
              "\n",
              "                clbr_A06      clbr_A07      clbr_A08      clbr_A09  \\\n",
              "date                                                                 \n",
              "2025-10-17 -3.000000e-02 -3.000000e-02 -7.000000e-02 -6.000000e-02   \n",
              "2025-10-20  5.000000e-02  4.000000e-02  4.000000e-02  2.000000e-02   \n",
              "2025-10-21  7.000000e-02  8.000000e-02  1.000000e-01  1.000000e-01   \n",
              "2025-10-22  1.000000e-02  0.000000e+00 -2.000000e-02 -2.000000e-02   \n",
              "2025-10-23 -2.000000e-01 -1.800000e-01 -1.800000e-01 -1.800000e-01   \n",
              "2025-10-24  4.000000e-02  4.000000e-02  3.000000e-02  4.000000e-02   \n",
              "2025-10-27  9.000000e-02  7.000000e-02  6.000000e-02  5.000000e-02   \n",
              "2025-10-28 -1.000000e-02  1.000000e-02  2.000000e-02  1.000000e-02   \n",
              "2025-10-29  1.000000e-02  1.000000e-02  1.000000e-02 -6.661338e-15   \n",
              "2025-10-30 -1.000000e-02 -1.000000e-02  0.000000e+00  1.000000e-02   \n",
              "2025-10-31  6.000000e-02  6.000000e-02  5.000000e-02  5.000000e-02   \n",
              "2025-11-03  0.000000e+00  0.000000e+00  2.000000e-02  2.000000e-02   \n",
              "2025-11-04 -1.000000e-02  1.000000e-02  0.000000e+00 -7.993606e-15   \n",
              "2025-11-05  1.000000e-02  2.000000e-02  3.000000e-02  3.000000e-02   \n",
              "2025-11-06  9.000000e-02  1.100000e-01  1.200000e-01  1.300000e-01   \n",
              "2025-11-07 -1.000000e-02  0.000000e+00  1.000000e-02  0.000000e+00   \n",
              "2025-11-10 -4.000000e-02 -5.000000e-02 -5.000000e-02 -4.000000e-02   \n",
              "2025-11-11 -3.000000e-02 -3.000000e-02 -3.000000e-02 -2.000000e-02   \n",
              "2025-11-12  1.000000e-02  1.000000e-02  7.105427e-15  0.000000e+00   \n",
              "2025-11-13 -8.000000e-02 -8.000000e-02 -6.000000e-02 -5.000000e-02   \n",
              "2025-11-14 -2.000000e-02 -2.000000e-02 -2.000000e-02 -2.000000e-02   \n",
              "2025-11-17  2.000000e-02 -1.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-11-18  1.000000e-02  2.000000e-02  2.000000e-02  0.000000e+00   \n",
              "2025-11-19 -2.000000e-02 -1.000000e-02 -3.000000e-02 -1.000000e-02   \n",
              "2025-11-20 -6.661338e-15 -2.000000e-02 -2.000000e-02 -2.000000e-02   \n",
              "2025-11-21 -1.000000e-02 -7.549517e-15 -1.000000e-02 -1.000000e-02   \n",
              "2025-11-24  5.000000e-02  2.000000e-02  1.000000e-02 -1.000000e-02   \n",
              "2025-11-25  4.000000e-02  4.000000e-02  3.000000e-02  2.000000e-02   \n",
              "2025-11-26  1.000000e-02  1.000000e-02  2.000000e-02  3.000000e-02   \n",
              "2025-11-27 -2.800000e-01 -2.900000e-01 -3.000000e-01 -3.000000e-01   \n",
              "2025-11-28  3.600000e-01  3.500000e-01  3.500000e-01  3.400000e-01   \n",
              "2025-12-01 -3.000000e-02 -1.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-12-02  2.000000e-02  1.000000e-02  7.105427e-15 -2.000000e-02   \n",
              "2025-12-03 -3.000000e-02 -3.000000e-02 -3.000000e-02 -4.000000e-02   \n",
              "2025-12-04  5.000000e-02  5.000000e-02  4.000000e-02  7.000000e-02   \n",
              "2025-12-05 -3.000000e-02 -3.000000e-02 -2.000000e-02 -3.000000e-02   \n",
              "2025-12-08  6.000000e-02  6.000000e-02  6.000000e-02  6.000000e-02   \n",
              "2025-12-09  4.000000e-02  5.000000e-02  6.000000e-02  7.000000e-02   \n",
              "2025-12-10 -1.000000e-02  0.000000e+00  1.000000e-02  0.000000e+00   \n",
              "2025-12-11 -6.000000e-02 -5.000000e-02 -4.000000e-02 -4.000000e-02   \n",
              "2025-12-12 -7.105427e-15 -1.000000e-02 -7.105427e-15  1.000000e-02   \n",
              "2025-12-15  3.000000e-02  2.000000e-02  1.000000e-02  7.105427e-15   \n",
              "2025-12-16  1.000000e-01  1.000000e-01  8.000000e-02  7.000000e-02   \n",
              "2025-12-17 -1.000000e-02 -1.000000e-02  7.105427e-15  1.000000e-02   \n",
              "2025-12-18  3.000000e-02  4.000000e-02  3.000000e-02  1.000000e-02   \n",
              "2025-12-19  1.000000e-02 -7.105427e-15 -1.000000e-02 -1.000000e-02   \n",
              "2025-12-22  3.000000e-02  0.000000e+00 -5.000000e-02 -3.000000e-02   \n",
              "2025-12-23 -2.000000e-02 -1.000000e-02  0.000000e+00 -1.000000e-02   \n",
              "2025-12-24  1.000000e-02 -1.000000e-02 -7.549517e-15 -6.661338e-15   \n",
              "2025-12-25  6.128000e+01  6.125000e+01  6.124000e+01  6.125000e+01   \n",
              "\n",
              "                clbr_A10      clbr_A11      clbr_A12      clbr_A13  \\\n",
              "date                                                                 \n",
              "2025-10-17 -7.000000e-02 -7.000000e-02 -7.000000e-02 -7.000000e-02   \n",
              "2025-10-20  3.000000e-02  3.000000e-02  4.000000e-02  3.000000e-02   \n",
              "2025-10-21  1.000000e-01  9.000000e-02  8.000000e-02  8.000000e-02   \n",
              "2025-10-22 -1.000000e-02 -7.993606e-15 -2.000000e-02 -1.000000e-02   \n",
              "2025-10-23 -1.800000e-01 -1.700000e-01 -1.600000e-01 -1.600000e-01   \n",
              "2025-10-24  4.000000e-02  2.000000e-02  4.000000e-02  4.000000e-02   \n",
              "2025-10-27  5.000000e-02  6.000000e-02  3.000000e-02  3.000000e-02   \n",
              "2025-10-28  1.000000e-02  1.000000e-02  1.000000e-02  1.000000e-02   \n",
              "2025-10-29  0.000000e+00  6.661338e-15 -1.000000e-02 -1.000000e-02   \n",
              "2025-10-30 -1.000000e-02 -1.000000e-02  1.000000e-02  1.000000e-02   \n",
              "2025-10-31  6.000000e-02  7.000000e-02  5.000000e-02  5.000000e-02   \n",
              "2025-11-03  1.000000e-02 -2.000000e-02  0.000000e+00  0.000000e+00   \n",
              "2025-11-04  0.000000e+00  2.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-11-05  2.000000e-02  1.000000e-02  3.000000e-02  3.000000e-02   \n",
              "2025-11-06  1.400000e-01  1.300000e-01  1.300000e-01  1.300000e-01   \n",
              "2025-11-07 -7.105427e-15  1.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-11-10 -4.000000e-02 -4.000000e-02 -3.000000e-02 -3.000000e-02   \n",
              "2025-11-11 -2.000000e-02 -1.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-11-12 -7.105427e-15 -1.000000e-02  7.105427e-15  7.105427e-15   \n",
              "2025-11-13 -4.000000e-02 -2.000000e-02 -3.000000e-02 -3.000000e-02   \n",
              "2025-11-14 -2.000000e-02 -2.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-11-17 -1.000000e-02 -2.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-11-18  0.000000e+00 -1.000000e-02 -2.000000e-02 -2.000000e-02   \n",
              "2025-11-19 -2.000000e-02 -2.000000e-02  1.000000e-02  1.000000e-02   \n",
              "2025-11-20 -2.000000e-02 -1.000000e-02 -3.000000e-02 -3.000000e-02   \n",
              "2025-11-21 -1.000000e-02 -1.000000e-02  0.000000e+00  0.000000e+00   \n",
              "2025-11-24  0.000000e+00 -2.000000e-02 -2.000000e-02 -2.000000e-02   \n",
              "2025-11-25  3.000000e-02  5.000000e-02  5.000000e-02  5.000000e-02   \n",
              "2025-11-26  3.000000e-02  2.000000e-02  2.000000e-02  2.000000e-02   \n",
              "2025-11-27 -3.000000e-01 -3.000000e-01 -3.000000e-01 -3.000000e-01   \n",
              "2025-11-28  3.300000e-01  3.300000e-01  3.300000e-01  3.300000e-01   \n",
              "2025-12-01 -1.000000e-02 -1.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-12-02 -2.000000e-02 -1.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-12-03 -4.000000e-02 -5.000000e-02 -5.000000e-02 -5.000000e-02   \n",
              "2025-12-04  5.000000e-02  5.000000e-02  5.000000e-02  5.000000e-02   \n",
              "2025-12-05 -2.000000e-02 -3.000000e-02 -3.000000e-02 -3.000000e-02   \n",
              "2025-12-08  6.000000e-02  8.000000e-02  8.000000e-02  8.000000e-02   \n",
              "2025-12-09  6.000000e-02  4.000000e-02  4.000000e-02  4.000000e-02   \n",
              "2025-12-10  2.000000e-02  3.000000e-02  3.000000e-02  3.000000e-02   \n",
              "2025-12-11 -4.000000e-02 -4.000000e-02 -4.000000e-02 -4.000000e-02   \n",
              "2025-12-12  2.000000e-02  2.000000e-02  2.000000e-02  2.000000e-02   \n",
              "2025-12-15  0.000000e+00  1.000000e-02  1.000000e-02  1.000000e-02   \n",
              "2025-12-16  6.000000e-02  5.000000e-02  5.000000e-02  5.000000e-02   \n",
              "2025-12-17  0.000000e+00 -1.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-12-18  1.000000e-02  2.000000e-02  2.000000e-02  2.000000e-02   \n",
              "2025-12-19 -2.000000e-02 -3.000000e-02 -3.000000e-02 -3.000000e-02   \n",
              "2025-12-22 -2.000000e-02  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "2025-12-23  7.105427e-15  7.105427e-15  7.105427e-15  7.105427e-15   \n",
              "2025-12-24 -1.000000e-02 -1.000000e-02 -1.000000e-02 -1.000000e-02   \n",
              "2025-12-25  6.127000e+01  6.127000e+01  6.127000e+01  6.127000e+01   \n",
              "\n",
              "                clbr_A14      clbr_A15  \n",
              "date                                    \n",
              "2025-10-17 -7.000000e-02 -7.000000e-02  \n",
              "2025-10-20  3.000000e-02  3.000000e-02  \n",
              "2025-10-21  8.000000e-02  8.000000e-02  \n",
              "2025-10-22 -1.000000e-02 -1.000000e-02  \n",
              "2025-10-23 -1.600000e-01 -1.600000e-01  \n",
              "2025-10-24  4.000000e-02  4.000000e-02  \n",
              "2025-10-27  3.000000e-02  3.000000e-02  \n",
              "2025-10-28  1.000000e-02  1.000000e-02  \n",
              "2025-10-29 -1.000000e-02 -1.000000e-02  \n",
              "2025-10-30  1.000000e-02  1.000000e-02  \n",
              "2025-10-31  5.000000e-02  5.000000e-02  \n",
              "2025-11-03  0.000000e+00  0.000000e+00  \n",
              "2025-11-04 -1.000000e-02 -1.000000e-02  \n",
              "2025-11-05  3.000000e-02  3.000000e-02  \n",
              "2025-11-06  1.300000e-01  1.300000e-01  \n",
              "2025-11-07 -1.000000e-02 -1.000000e-02  \n",
              "2025-11-10 -3.000000e-02 -3.000000e-02  \n",
              "2025-11-11 -1.000000e-02 -1.000000e-02  \n",
              "2025-11-12  7.105427e-15  7.105427e-15  \n",
              "2025-11-13 -3.000000e-02 -3.000000e-02  \n",
              "2025-11-14 -1.000000e-02 -1.000000e-02  \n",
              "2025-11-17 -1.000000e-02 -1.000000e-02  \n",
              "2025-11-18 -2.000000e-02 -2.000000e-02  \n",
              "2025-11-19  1.000000e-02  1.000000e-02  \n",
              "2025-11-20 -3.000000e-02 -3.000000e-02  \n",
              "2025-11-21  0.000000e+00  0.000000e+00  \n",
              "2025-11-24 -2.000000e-02 -2.000000e-02  \n",
              "2025-11-25  5.000000e-02  5.000000e-02  \n",
              "2025-11-26  2.000000e-02  2.000000e-02  \n",
              "2025-11-27 -3.000000e-01 -3.000000e-01  \n",
              "2025-11-28  3.300000e-01  3.300000e-01  \n",
              "2025-12-01 -1.000000e-02 -1.000000e-02  \n",
              "2025-12-02 -1.000000e-02 -1.000000e-02  \n",
              "2025-12-03 -5.000000e-02 -5.000000e-02  \n",
              "2025-12-04  5.000000e-02  5.000000e-02  \n",
              "2025-12-05 -3.000000e-02 -3.000000e-02  \n",
              "2025-12-08  8.000000e-02  8.000000e-02  \n",
              "2025-12-09  4.000000e-02  4.000000e-02  \n",
              "2025-12-10  3.000000e-02  3.000000e-02  \n",
              "2025-12-11 -4.000000e-02 -4.000000e-02  \n",
              "2025-12-12  2.000000e-02  2.000000e-02  \n",
              "2025-12-15  1.000000e-02  1.000000e-02  \n",
              "2025-12-16  5.000000e-02  5.000000e-02  \n",
              "2025-12-17 -1.000000e-02 -1.000000e-02  \n",
              "2025-12-18  2.000000e-02  2.000000e-02  \n",
              "2025-12-19 -3.000000e-02 -3.000000e-02  \n",
              "2025-12-22  0.000000e+00  0.000000e+00  \n",
              "2025-12-23  7.105427e-15  7.105427e-15  \n",
              "2025-12-24 -1.000000e-02 -1.000000e-02  \n",
              "2025-12-25  6.127000e+01  6.127000e+01  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_returns.tail(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Build Position Vector (w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  J6 (A02): -268.0004 lots\n",
            "  N6 (A05): 300.0 lots\n",
            "  U6 (A07): 850.0 lots\n",
            "  V6 (A08): -850.0 lots\n",
            "  Z6 (A10): 100.0 lots\n",
            "\n",
            "Node position vector:\n",
            "A01      0.0000\n",
            "A02   -268.0004\n",
            "A03      0.0000\n",
            "A04      0.0000\n",
            "A05    300.0000\n",
            "A06      0.0000\n",
            "A07    850.0000\n",
            "A08   -850.0000\n",
            "A09      0.0000\n",
            "A10    100.0000\n",
            "A11      0.0000\n",
            "A12      0.0000\n",
            "A13      0.0000\n",
            "A14      0.0000\n",
            "A15      0.0000\n",
            "Name: lots, dtype: float64\n",
            "\n",
            "Bucket positions:\n",
            "  Front: [   0.     -268.0004    0.        0.    ]\n",
            "  Mid: [ 300.    0.  850. -850.]\n",
            "  Back: [  0. 100.   0.   0.   0.   0.   0.]\n"
          ]
        }
      ],
      "source": [
        "# Build node position vector from contract codes\n",
        "# Initialize all nodes to zero\n",
        "all_nodes = [f\"A{i:02d}\" for i in range(1, 16)]\n",
        "w_node = pd.Series(0.0, index=all_nodes, name='lots')\n",
        "\n",
        "# Map contract positions to nodes\n",
        "for contract, lots in pos_codes.items():\n",
        "    if contract in contract_to_node:\n",
        "        node = contract_to_node[contract]\n",
        "        w_node[node] = lots\n",
        "        print(f\"  {contract} ({node}): {lots} lots\")\n",
        "\n",
        "print(f\"\\nNode position vector:\")\n",
        "print(w_node)\n",
        "\n",
        "# Create bucket position vectors\n",
        "w_front = w_node[front].values\n",
        "w_mid = w_node[mid].values\n",
        "w_back = w_node[back].values\n",
        "w_total = w_node.values\n",
        "\n",
        "print(f\"\\nBucket positions:\")\n",
        "print(f\"  Front: {w_front}\")\n",
        "print(f\"  Mid: {w_mid}\")\n",
        "print(f\"  Back: {w_back}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. EWMA Covariance Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing EWMA covariances...\n",
            "\n",
            "Front covariance shape: (4, 4)\n",
            "Mid covariance shape: (4, 4)\n",
            "Back covariance shape: (7, 7)\n",
            "\n",
            "Total covariance shape: (15, 15)\n"
          ]
        }
      ],
      "source": [
        "def compute_ewma_covariance(returns_df, nodes, lambda_val, init_obs=60):\n",
        "    \"\"\"\n",
        "    Compute EWMA covariance matrix for given nodes.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    returns_df : DataFrame\n",
        "        DataFrame with returns (daily changes)\n",
        "    nodes : list\n",
        "        List of node names (e.g., ['A01', 'A02', ...])\n",
        "    lambda_val : float\n",
        "        EWMA decay parameter\n",
        "    init_obs : int\n",
        "        Number of observations to use for initial covariance\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    cov_matrix : ndarray\n",
        "        Final EWMA covariance matrix\n",
        "    \"\"\"\n",
        "    # Extract relevant columns\n",
        "    cols = [f'{product}_{node}' for node in nodes]\n",
        "    returns_subset = returns_df[cols].values\n",
        "    \n",
        "    n_obs, n_nodes = returns_subset.shape\n",
        "    \n",
        "    if n_obs < init_obs:\n",
        "        raise ValueError(f\"Need at least {init_obs} observations, got {n_obs}\")\n",
        "    \n",
        "    # Initialize with sample covariance of first N observations\n",
        "    init_returns = returns_subset[:init_obs]\n",
        "    # Remove any rows with NaN\n",
        "    init_returns = init_returns[~np.isnan(init_returns).any(axis=1)]\n",
        "    \n",
        "    if len(init_returns) < 10:\n",
        "        # Fallback: use identity matrix scaled by variance\n",
        "        cov_current = np.eye(n_nodes) * np.var(returns_subset, axis=0).mean()\n",
        "    else:\n",
        "        cov_current = np.cov(init_returns.T)\n",
        "    \n",
        "    # EWMA recursion: Î£_t = Î» * Î£_{t-1} + (1-Î») * r_t * r_t'\n",
        "    for t in range(init_obs, n_obs):\n",
        "        r_t = returns_subset[t:t+1, :]  # Shape: (1, n_nodes)\n",
        "        \n",
        "        # Skip if any NaN\n",
        "        if np.isnan(r_t).any():\n",
        "            continue\n",
        "        \n",
        "        # EWMA update\n",
        "        outer_product = np.outer(r_t, r_t)\n",
        "        cov_current = lambda_val * cov_current + (1 - lambda_val) * outer_product[0]\n",
        "    \n",
        "    return cov_current\n",
        "\n",
        "# Compute EWMA covariance for each bucket\n",
        "print(\"Computing EWMA covariances...\")\n",
        "\n",
        "Sigma_front = compute_ewma_covariance(df_returns, front, lambda_front, ewma_init_obs)\n",
        "Sigma_mid = compute_ewma_covariance(df_returns, mid, lambda_mid, ewma_init_obs)\n",
        "Sigma_back = compute_ewma_covariance(df_returns, back, lambda_back, ewma_init_obs)\n",
        "\n",
        "print(f\"\\nFront covariance shape: {Sigma_front.shape}\")\n",
        "print(f\"Mid covariance shape: {Sigma_mid.shape}\")\n",
        "print(f\"Back covariance shape: {Sigma_back.shape}\")\n",
        "\n",
        "# Build total covariance matrix (block-diagonal for now, Option 1)\n",
        "# TODO: Option 2 - add cross-bucket correlations using lambda_cross\n",
        "n_front = len(front)\n",
        "n_mid = len(mid)\n",
        "n_back = len(back)\n",
        "n_total = n_front + n_mid + n_back\n",
        "\n",
        "Sigma_total = np.zeros((n_total, n_total))\n",
        "Sigma_total[:n_front, :n_front] = Sigma_front\n",
        "Sigma_total[n_front:n_front+n_mid, n_front:n_front+n_mid] = Sigma_mid\n",
        "Sigma_total[n_front+n_mid:, n_front+n_mid:] = Sigma_back\n",
        "\n",
        "print(f\"\\nTotal covariance shape: {Sigma_total.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Bucket Summary DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bucket Summary:\n",
            "bucket  standalone_Q  MC_to_total Q_check MC_signed\n",
            " Front  2.861847e+06 2.091604e+06      OK       POS\n",
            "   Mid  2.601440e+06 1.728280e+06      OK       POS\n",
            "  Back  6.126386e+05 9.585071e+04      OK       POS\n",
            " TOTAL  3.915735e+06          NaN      OK      ZERO\n",
            "\n",
            "Note: MC_signed shows whether the bucket contributes positively (POS) or negatively (NEG) to total portfolio risk.\n",
            "      A negative MC indicates the bucket provides diversification/hedging benefits to the overall portfolio.\n",
            "\n",
            "âœ“ Sanity checks passed\n"
          ]
        }
      ],
      "source": [
        "def compute_q_risk(w, Sigma):\n",
        "    \"\"\"Compute Q risk: Q = 1000 * sqrt(w' Î£ w)\"\"\"\n",
        "    var = w.T @ Sigma @ w\n",
        "    if var < 0:\n",
        "        return 0.0\n",
        "    return 1000 * np.sqrt(var)\n",
        "\n",
        "def compute_mc_to_total(w_bucket, w_total, Sigma_total, bucket_start_idx, bucket_nodes):\n",
        "    \"\"\"\n",
        "    Compute marginal contribution of bucket to total portfolio.\n",
        "    MC_bucket = 1000 * (w_bucket' Î£_total w_total) / sqrt(w_total' Î£_total w_total)\n",
        "    \"\"\"\n",
        "    # Map bucket positions to total vector\n",
        "    w_bucket_in_total = np.zeros(len(w_total))\n",
        "    w_bucket_in_total[bucket_start_idx:bucket_start_idx+len(bucket_nodes)] = w_bucket\n",
        "    \n",
        "    # Compute numerator: w_bucket' Î£_total w_total\n",
        "    numerator = w_bucket_in_total.T @ Sigma_total @ w_total\n",
        "    \n",
        "    # Compute denominator: sqrt(w_total' Î£_total w_total)\n",
        "    total_var = w_total.T @ Sigma_total @ w_total\n",
        "    if total_var <= 0:\n",
        "        return 0.0\n",
        "    denominator = np.sqrt(total_var)\n",
        "    \n",
        "    return 1000 * numerator / denominator\n",
        "\n",
        "# Compute standalone Q for each bucket\n",
        "Q_front = compute_q_risk(w_front, Sigma_front)\n",
        "Q_mid = compute_q_risk(w_mid, Sigma_mid)\n",
        "Q_back = compute_q_risk(w_back, Sigma_back)\n",
        "Q_total = compute_q_risk(w_total, Sigma_total)\n",
        "\n",
        "# Compute MC to total\n",
        "MC_front = compute_mc_to_total(w_front, w_total, Sigma_total, 0, front)\n",
        "MC_mid = compute_mc_to_total(w_mid, w_total, Sigma_total, n_front, mid)\n",
        "MC_back = compute_mc_to_total(w_back, w_total, Sigma_total, n_front + n_mid, back)\n",
        "\n",
        "# Build bucket_summary_df\n",
        "bucket_summary_df = pd.DataFrame({\n",
        "    'bucket': ['Front', 'Mid', 'Back', 'TOTAL'],\n",
        "    'standalone_Q': [Q_front, Q_mid, Q_back, Q_total],\n",
        "    'MC_to_total': [MC_front, MC_mid, MC_back, np.nan],\n",
        "})\n",
        "\n",
        "# Sanity checks\n",
        "bucket_summary_df['Q_check'] = bucket_summary_df['standalone_Q'].apply(lambda x: 'OK' if x >= 0 and np.isfinite(x) else 'FAIL')\n",
        "\n",
        "# MC_signed indicates the sign of the marginal contribution to total portfolio risk:\n",
        "# - POS: Positive MC - this bucket increases total portfolio risk (diversification benefit < standalone risk)\n",
        "# - NEG: Negative MC - this bucket decreases total portfolio risk (diversification benefit > standalone risk, i.e., hedging effect)\n",
        "# - ZERO: Zero MC - this bucket has no net contribution to total risk (perfectly hedged or no positions)\n",
        "bucket_summary_df['MC_signed'] = bucket_summary_df['MC_to_total'].apply(lambda x: 'POS' if x > 0 else 'NEG' if x < 0 else 'ZERO')\n",
        "\n",
        "print(\"Bucket Summary:\")\n",
        "print(bucket_summary_df.to_string(index=False))\n",
        "print(\"\\nNote: MC_signed shows whether the bucket contributes positively (POS) or negatively (NEG) to total portfolio risk.\")\n",
        "print(\"      A negative MC indicates the bucket provides diversification/hedging benefits to the overall portfolio.\")\n",
        "\n",
        "# Assertions\n",
        "assert Q_total >= 0, \"Total Q must be non-negative\"\n",
        "assert np.isfinite(Q_total), \"Total Q must be finite\"\n",
        "assert all(bucket_summary_df['standalone_Q'] >= 0), \"All bucket Qs must be non-negative\"\n",
        "print(\"\\nâœ“ Sanity checks passed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bucket</th>\n",
              "      <th>standalone_Q</th>\n",
              "      <th>MC_to_total</th>\n",
              "      <th>Q_check</th>\n",
              "      <th>MC_signed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Front</td>\n",
              "      <td>157848.809798</td>\n",
              "      <td>130206.517630</td>\n",
              "      <td>OK</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mid</td>\n",
              "      <td>107519.532370</td>\n",
              "      <td>60412.225439</td>\n",
              "      <td>OK</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Back</td>\n",
              "      <td>11905.461918</td>\n",
              "      <td>740.700437</td>\n",
              "      <td>OK</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TOTAL</td>\n",
              "      <td>191359.443506</td>\n",
              "      <td>NaN</td>\n",
              "      <td>OK</td>\n",
              "      <td>ZERO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  bucket   standalone_Q    MC_to_total Q_check MC_signed\n",
              "0  Front  157848.809798  130206.517630      OK       POS\n",
              "1    Mid  107519.532370   60412.225439      OK       POS\n",
              "2   Back   11905.461918     740.700437      OK       POS\n",
              "3  TOTAL  191359.443506            NaN      OK      ZERO"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bucket_summary_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Factor Detail DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building factor detail DataFrames...\n",
            "\n",
            "Front bucket positions: [  100. -1400. -1974. -1400.]\n",
            "Front bucket total net position: -4674.0\n",
            "Front Level factor vector (B[:, 0]): [0.25 0.25 0.25 0.25]\n",
            "\n",
            "Mathematical check:\n",
            "  If Level exposure = e_level, then Level contributes (1/4)*e_level to each node\n",
            "  Level contribution per node = (1/4) * e_level\n",
            "  Sum of all node positions = 4 * (1/4) * e_level = e_level\n",
            "  Therefore: e_level = sum(positions) = -4674.0\n",
            "\n",
            "Front Level qty_lots (factor exposure): -4674.0\n",
            "  Level contribution to each node: (1/4) * -4674.0 = -1168.5\n",
            "  But this is just the Level component - spreads adjust from this base\n",
            "Front: MC_to_total=130206.52, recon_error=0.00e+00\n",
            "Mid: MC_to_total=60412.23, recon_error=0.00e+00\n",
            "Back: MC_to_total=740.70, recon_error=1.94e+02\n",
            "\n",
            "Factor Detail DataFrame:\n",
            "bucket   factor_name      qty_lots  marginal_slope   MC_$per_day  pct_of_bucket_Q AS_skew_direction\n",
            " Front         Level -4.674000e+03   -5.330819e+00  1.302065e+05     1.000000e+02               BUY\n",
            " Front       A01/A02  1.268500e+03    3.335444e-13  2.211028e-09     1.698093e-12              SELL\n",
            " Front       A02/A03  1.037000e+03    5.026890e-13  2.724133e-09     2.092163e-12              SELL\n",
            " Front       A03/A04  2.315000e+02   -1.856542e-12 -2.245980e-09    -1.724937e-12               BUY\n",
            "   Mid         Level  4.600000e+03    2.513141e+00  6.041223e+04     1.000000e+02              SELL\n",
            "   Mid       A05/A06  3.500000e+02    8.681766e-10  1.587911e-06     2.628460e-09              SELL\n",
            "   Mid       A06/A07  7.000000e+02    3.985412e-09  1.457879e-05     2.413218e-08              SELL\n",
            "   Mid       A07/A08  1.050000e+03    1.115864e-08  6.122806e-05     1.013505e-07              SELL\n",
            "  Back         Level -6.750000e+02   -2.099667e-01  7.406349e+02     9.999116e+01               BUY\n",
            "  Back Block1-Block2 -7.105427e-14    2.553320e-05 -9.480812e-18    -1.279979e-18              SELL\n",
            "  Back Block2-Block3 -3.126388e-13   -1.952321e-05  3.189659e-17     4.306274e-18               BUY\n",
            "  Back    Early-Late  2.357143e+02    4.668707e-06  5.750858e-03     7.764081e-04              SELL\n",
            "  Back       A09/A12  1.375000e+02    4.438755e-05  3.189437e-02     4.305974e-03              SELL\n",
            "  Back      residual  1.944544e+02    2.740944e-05  2.785275e-02     3.760325e-03           NEUTRAL\n",
            "\n",
            "================================================================================\n",
            "FACTOR MCs USE FULL COVARIANCE MATRIX\n",
            "================================================================================\n",
            "Factor MCs in factor_detail_df are computed using the FULL covariance matrix (Î£_total):\n",
            "  Front Level MC (contribution to total portfolio): 130206.52\n",
            "  Mid Level MC (contribution to total portfolio): 60412.23\n",
            "  Sum of Level MCs: 190618.74\n",
            "\n",
            "  Front bucket MC_to_total: 130206.52\n",
            "  Mid bucket MC_to_total: 60412.23\n",
            "  Sum of bucket MCs: 190618.74\n",
            "  Total Q: 191359.44\n",
            "\n",
            "  Key insight:\n",
            "  - Factor MCs show contribution to TOTAL portfolio risk (using Î£_total)\n",
            "  - Factor MCs within each bucket sum to that bucket's MC_to_total\n",
            "  - This accounts for cross-bucket correlations and diversification effects\n",
            "  - Sum of all factor MCs across all buckets = Total Q\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "FACTOR DECOMPOSITION EXPLANATION:\n",
            "================================================================================\n",
            "For Front/Mid buckets, factors are: Level + adjacent spreads\n",
            "\n",
            "Level Factor:\n",
            "  - Level factor vector: [1/n, 1/n, ..., 1/n] = [0.25, 0.25, 0.25, 0.25] for Front\n",
            "  - Level exposure (qty_lots) = TOTAL NET POSITION across all nodes\n",
            "  - Mathematical relationship:\n",
            "    * Level contributes (1/n) * e_level to each node\n",
            "    * Sum of all positions = n * (1/n) * e_level = e_level\n",
            "    * Therefore: Level exposure = sum(positions)\n",
            "\n",
            "  Example:\n",
            "    * Node positions: [  100. -1400. -1974. -1400.]\n",
            "    * Total net position: -4674.0\n",
            "    * Level exposure: -4674.0 (NOT the average!)\n",
            "    * Level contributes -1168 to each node (before spreads)\n",
            "\n",
            "Spread Factors:\n",
            "  - Each spread (e.g., A01/A02) represents the difference between adjacent nodes\n",
            "  - Spread exposures adjust positions from the Level base\n",
            "  - Final position = Level contribution + spread adjustments\n",
            "\n",
            "  Example reconstruction:\n",
            "    * A01 final = 100.0\n",
            "    * A01 = Level_base + spread_adjustments\n",
            "    * Level_base = (1/4) * -4674.0 = -1168\n",
            "    * Spread adjustments = 1268\n",
            "================================================================================\n",
            "\n",
            "âœ“ Front MC_to_total tie-out (computed vs bucket_summary): 130206.52 vs 130206.52 (error: 0.000000)\n",
            "\n",
            "âœ“ Mid MC_to_total tie-out (computed vs bucket_summary): 60412.23 vs 60412.23 (error: 0.000000)\n",
            "\n",
            "âœ“ Back MC_to_total tie-out (computed vs bucket_summary): 740.70 vs 740.70 (error: 0.000000)\n",
            "âœ“ Front factor MC sum tie-out: 130206.52 vs 130206.52 (error: 0.000000)\n",
            "âœ“ Mid factor MC sum tie-out: 60412.23 vs 60412.23 (error: 0.000000)\n",
            "âœ“ Back factor MC sum tie-out: 740.70 vs 740.70 (error: 0.000000)\n"
          ]
        }
      ],
      "source": [
        "def build_factor_matrix_bucket(nodes, bucket_type='front'):\n",
        "    \"\"\"\n",
        "    Build factor matrix B for a bucket.\n",
        "    \n",
        "    For Front/Mid: Level + adjacent spreads (A01/A02, A02/A03, etc)\n",
        "    For Back: Level + longer spreads + residual\n",
        "    \"\"\"\n",
        "    n_nodes = len(nodes)\n",
        "    \n",
        "    if bucket_type in ['front', 'mid']:\n",
        "        # Level factor: equal weight\n",
        "        level_factor = np.ones(n_nodes) / n_nodes\n",
        "        \n",
        "        # Adjacent spreads\n",
        "        spread_factors = []\n",
        "        for i in range(n_nodes - 1):\n",
        "            spread = np.zeros(n_nodes)\n",
        "            spread[i] = 1\n",
        "            spread[i+1] = -1\n",
        "            spread_factors.append(spread)\n",
        "        \n",
        "        # Combine: Level + spreads\n",
        "        B = np.column_stack([level_factor] + spread_factors)\n",
        "        factor_names = ['Level'] + [f\"{nodes[i]}/{nodes[i+1]}\" for i in range(n_nodes-1)]\n",
        "        \n",
        "        return B, factor_names, None  # No residual for front/mid\n",
        "    \n",
        "    else:  # back bucket\n",
        "        # Level factor: equal weight\n",
        "        level_factor = np.ones(n_nodes) / n_nodes\n",
        "        \n",
        "        # Longer/coarse spreads\n",
        "        # Block1: A09-A11, Block2: A12-A13, Block3: A14-A15\n",
        "        # Block averages\n",
        "        block1_avg = np.zeros(n_nodes)\n",
        "        block1_avg[:3] = 1.0/3  # A09, A10, A11\n",
        "        \n",
        "        block2_avg = np.zeros(n_nodes)\n",
        "        block2_avg[3:5] = 1.0/2  # A12, A13\n",
        "        \n",
        "        block3_avg = np.zeros(n_nodes)\n",
        "        block3_avg[5:] = 1.0/2  # A14, A15\n",
        "        \n",
        "        # Coarse spreads\n",
        "        spread1 = block1_avg - block2_avg  # Block1 - Block2\n",
        "        spread2 = block2_avg - block3_avg  # Block2 - Block3\n",
        "        \n",
        "        # Early-back vs late-back\n",
        "        early_back = np.zeros(n_nodes)\n",
        "        early_back[:4] = 1.0/4  # A09-A12\n",
        "        late_back = np.zeros(n_nodes)\n",
        "        late_back[4:] = 1.0/3  # A13-A15\n",
        "        spread3 = early_back - late_back\n",
        "        \n",
        "        # Additional spread: A09/A12 (skip some nodes)\n",
        "        spread4 = np.zeros(n_nodes)\n",
        "        spread4[0] = 1  # A09\n",
        "        spread4[3] = -1  # A12\n",
        "        \n",
        "        # Combine factors\n",
        "        B_coarse = np.column_stack([level_factor, spread1, spread2, spread3, spread4])\n",
        "        factor_names_coarse = ['Level', 'Block1-Block2', 'Block2-Block3', 'Early-Late', 'A09/A12']\n",
        "        \n",
        "        return B_coarse, factor_names_coarse, 'residual'\n",
        "\n",
        "def compute_factor_risk_metrics(w_bucket, Sigma_bucket, B, factor_names, Sigma_total, w_total, bucket_start_idx, n_total, residual_name=None):\n",
        "    \"\"\"\n",
        "    Compute factor-level risk metrics using FULL covariance matrix.\n",
        "    \n",
        "    Factor decomposition: w = B * e, where:\n",
        "    - w: node positions (n_nodes x 1)\n",
        "    - B: factor matrix (n_nodes x n_factors), columns are factor loadings\n",
        "    - e: factor exposures (n_factors x 1)\n",
        "    \n",
        "    For Level factor: B[:, 0] = [1/n, 1/n, ..., 1/n] (equal weight)\n",
        "    Level exposure e[0] represents the total net position across all nodes.\n",
        "    \n",
        "    This function uses Sigma_total (full covariance) for risk calculations, so factor MCs\n",
        "    show contribution to TOTAL portfolio risk and sum to bucket MC_to_total.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    w_bucket : ndarray\n",
        "        Bucket node positions\n",
        "    Sigma_bucket : ndarray\n",
        "        Bucket covariance matrix (used only for factor exposure calculation)\n",
        "    B : ndarray\n",
        "        Bucket factor matrix\n",
        "    factor_names : list\n",
        "        Factor names\n",
        "    Sigma_total : ndarray\n",
        "        Full covariance matrix (n_total x n_total)\n",
        "    w_total : ndarray\n",
        "        Full portfolio positions (n_total x 1)\n",
        "    bucket_start_idx : int\n",
        "        Starting index of bucket nodes in full space\n",
        "    n_total : int\n",
        "        Total number of nodes\n",
        "    residual_name : str, optional\n",
        "        Name for residual factor (for back bucket)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    factor_df : DataFrame with columns: factor_name, qty_lots, marginal_slope, MC_$per_day, pct_of_bucket_Q, AS_skew_direction\n",
        "    bucket_MC_to_total : float\n",
        "        Bucket MC to total (for tie-out verification)\n",
        "    recon_error : float\n",
        "        Reconstruction error\n",
        "    \"\"\"\n",
        "    # Factor exposures: e such that w = B * e\n",
        "    # For square invertible B: e = B^{-1} w\n",
        "    # For non-square or non-invertible: e = (B^T B)^{-1} B^T w (least squares)\n",
        "    if B.shape[0] == B.shape[1]:\n",
        "        # Square matrix - try direct inverse\n",
        "        try:\n",
        "            B_inv = np.linalg.inv(B)\n",
        "            e = B_inv @ w_bucket\n",
        "        except np.linalg.LinAlgError:\n",
        "            # Not invertible, use pseudoinverse\n",
        "            e = np.linalg.pinv(B) @ w_bucket\n",
        "    else:\n",
        "        # Non-square, use least squares\n",
        "        e = np.linalg.lstsq(B, w_bucket, rcond=None)[0]\n",
        "    \n",
        "    # Verify: Level exposure should equal sum of node positions\n",
        "    # (since Level = [1/n, 1/n, ..., 1/n], Level exposure = sum(w) / n * n = sum(w))\n",
        "    level_idx = factor_names.index('Level') if 'Level' in factor_names else None\n",
        "    if level_idx is not None:\n",
        "        level_exposure = e[level_idx]\n",
        "        total_net_position = w_bucket.sum()\n",
        "        # Mathematical check: For Level = [1/n, 1/n, ..., 1/n], if w = B * e, then:\n",
        "        # sum(w) = sum(B[:, 0]) * e_level + sum(B[:, 1]) * e_spread1 + ... \n",
        "        # Since sum(B[:, i]) = 0 for all spreads (they're differences), and sum(B[:, 0]) = n * (1/n) = 1,\n",
        "        # we get: sum(w) = 1 * e_level, so e_level = sum(w)\n",
        "        # This means Level exposure equals total net position, which is correct.\n",
        "        level_check = abs(level_exposure - total_net_position)\n",
        "        if level_check > 1e-6:\n",
        "            print(f\"WARNING: Level exposure ({level_exposure:.2f}) != total net position ({total_net_position:.2f}), diff={level_check:.6f}\")\n",
        "    \n",
        "    # Map bucket factor matrix B to full space: B_full (n_total x n_factors)\n",
        "    n_bucket_nodes = B.shape[0]\n",
        "    n_factors = B.shape[1]\n",
        "    B_full = np.zeros((n_total, n_factors))\n",
        "    B_full[bucket_start_idx:bucket_start_idx+n_bucket_nodes, :] = B\n",
        "    \n",
        "    # Map bucket positions to full space for residual calculation\n",
        "    w_bucket_in_total = np.zeros(n_total)\n",
        "    w_bucket_in_total[bucket_start_idx:bucket_start_idx+n_bucket_nodes] = w_bucket\n",
        "    \n",
        "    # Factor covariance using FULL covariance matrix: Î£_f = B_full' Î£_total B_full\n",
        "    Sigma_f = B_full.T @ Sigma_total @ B_full\n",
        "    \n",
        "    # Compute total portfolio variance for MC normalization\n",
        "    total_var = w_total.T @ Sigma_total @ w_total\n",
        "    sqrt_total_var = np.sqrt(total_var) if total_var > 0 else 1e-10\n",
        "    \n",
        "    # Compute bucket MC to total for tie-out verification\n",
        "    # MC_bucket = 1000 * (w_bucket_in_total' Î£_total w_total) / sqrt(w_total' Î£_total w_total)\n",
        "    bucket_mc_numerator = w_bucket_in_total.T @ Sigma_total @ w_total\n",
        "    bucket_MC_to_total = 1000 * bucket_mc_numerator / sqrt_total_var if sqrt_total_var > 1e-10 else 0.0\n",
        "    \n",
        "    # Marginal risk slopes using full covariance: slope_f = B_full' Î£_total w_total\n",
        "    # This gives the marginal contribution of each factor to total portfolio risk\n",
        "    slope_f = B_full.T @ Sigma_total @ w_total\n",
        "    \n",
        "    # Factor MCs using Euler allocation: MC_factor = 1000 * (e * slope_f) / sqrt(w_total' Î£_total w_total)\n",
        "    # This ensures sum(MC_factor) = bucket_MC_to_total\n",
        "    # Proof: sum(MC_factor) = 1000 * sum(e * slope_f) / sqrt_total_var\n",
        "    #                      = 1000 * (e' slope_f) / sqrt_total_var\n",
        "    #                      = 1000 * (e' B_full' Î£_total w_total) / sqrt_total_var\n",
        "    #                      = 1000 * (w_bucket_in_total' Î£_total w_total) / sqrt_total_var\n",
        "    #                      = bucket_MC_to_total\n",
        "    MC_factor = 1000 * (e * slope_f) / sqrt_total_var if sqrt_total_var > 1e-10 else np.zeros(len(e))\n",
        "    \n",
        "    # Verify reconstruction: w_recon = B * e should equal w_bucket (within numerical tolerance)\n",
        "    w_recon = B @ e\n",
        "    recon_error = np.linalg.norm(w_recon - w_bucket)\n",
        "    \n",
        "    # Percentage of bucket MC_to_total (not standalone Q)\n",
        "    if abs(bucket_MC_to_total) > 1e-10:\n",
        "        pct_of_bucket_MC = 100 * MC_factor / bucket_MC_to_total\n",
        "    else:\n",
        "        pct_of_bucket_MC = np.zeros(len(e))\n",
        "    \n",
        "    # AS skew direction\n",
        "    AS_direction = pd.Series(slope_f).apply(lambda x: 'SELL' if x > 0 else 'BUY' if x < 0 else 'NEUTRAL')\n",
        "    \n",
        "    # Build DataFrame\n",
        "    factor_df = pd.DataFrame({\n",
        "        'factor_name': factor_names,\n",
        "        'qty_lots': e,\n",
        "        'marginal_slope': slope_f,\n",
        "        'MC_$per_day': MC_factor,\n",
        "        'pct_of_bucket_Q': pct_of_bucket_MC,  # Now percentage of bucket MC_to_total\n",
        "        'AS_skew_direction': AS_direction\n",
        "    })\n",
        "    \n",
        "    # Handle residual if needed\n",
        "    if residual_name:\n",
        "        # Compute residual component using full covariance\n",
        "        # Project bucket positions onto factor space: w_exp = B * e (already computed as w_recon)\n",
        "        # But we need to compute the projection using full covariance for MC calculation\n",
        "        # P_bucket = B (B' Î£_bucket B)^+ B' Î£_bucket (for exposure calculation)\n",
        "        # For MC, we need: residual_MC = MC(w_bucket) - MC(w_exp) where w_exp is in factor space\n",
        "        \n",
        "        # Compute projected bucket positions in factor space\n",
        "        w_exp_bucket = B @ e  # This is w_recon, the projection onto factor space\n",
        "        \n",
        "        # Residual bucket positions (what's not explained by factors)\n",
        "        w_res_bucket = w_bucket - w_exp_bucket\n",
        "        \n",
        "        # Map residual to full space for MC calculation\n",
        "        w_res_full = np.zeros(n_total)\n",
        "        w_res_full[bucket_start_idx:bucket_start_idx+n_bucket_nodes] = w_res_bucket\n",
        "        \n",
        "        # Residual risk contribution (Euler) using full covariance\n",
        "        if np.linalg.norm(w_res_bucket) > 1e-10:\n",
        "            # Residual MC = 1000 * (w_res_full' Î£_total w_total) / sqrt(w_total' Î£_total w_total)\n",
        "            residual_MC = 1000 * (w_res_full.T @ Sigma_total @ w_total) / sqrt_total_var if sqrt_total_var > 1e-10 else 0.0\n",
        "            # Residual slope: marginal contribution of residual to total portfolio risk\n",
        "            residual_slope = (w_res_full.T @ Sigma_total @ w_total) / np.linalg.norm(w_res_bucket) if np.linalg.norm(w_res_bucket) > 1e-10 else 0\n",
        "            \n",
        "            residual_row = pd.DataFrame({\n",
        "                'factor_name': [residual_name],\n",
        "                'qty_lots': [np.linalg.norm(w_res_bucket)],\n",
        "                'marginal_slope': [residual_slope],\n",
        "                'MC_$per_day': [residual_MC],\n",
        "                'pct_of_bucket_Q': [100 * residual_MC / bucket_MC_to_total if abs(bucket_MC_to_total) > 1e-10 else 0],\n",
        "                'AS_skew_direction': ['NEUTRAL']\n",
        "            })\n",
        "            \n",
        "            factor_df = pd.concat([factor_df, residual_row], ignore_index=True)\n",
        "    \n",
        "    return factor_df, bucket_MC_to_total, recon_error\n",
        "\n",
        "# Build factor detail for each bucket\n",
        "print(\"Building factor detail DataFrames...\")\n",
        "\n",
        "# Front bucket\n",
        "B_front, factor_names_front, _ = build_factor_matrix_bucket(front, 'front')\n",
        "print(f\"\\nFront bucket positions: {w_front}\")\n",
        "print(f\"Front bucket total net position: {w_front.sum()}\")\n",
        "print(f\"Front Level factor vector (B[:, 0]): {B_front[:, 0]}\")\n",
        "print(f\"\\nMathematical check:\")\n",
        "print(f\"  If Level exposure = e_level, then Level contributes (1/4)*e_level to each node\")\n",
        "print(f\"  Level contribution per node = (1/4) * e_level\")\n",
        "print(f\"  Sum of all node positions = 4 * (1/4) * e_level = e_level\")\n",
        "print(f\"  Therefore: e_level = sum(positions) = {w_front.sum()}\")\n",
        "factor_detail_front, MC_front_check, recon_error_front = compute_factor_risk_metrics(\n",
        "    w_front, Sigma_front, B_front, factor_names_front, \n",
        "    Sigma_total, w_total, 0, n_total\n",
        ")\n",
        "factor_detail_front.insert(0, 'bucket', 'Front')\n",
        "level_exposure = factor_detail_front[factor_detail_front['factor_name'] == 'Level']['qty_lots'].values[0]\n",
        "print(f\"\\nFront Level qty_lots (factor exposure): {level_exposure}\")\n",
        "print(f\"  Level contribution to each node: (1/4) * {level_exposure} = {0.25 * level_exposure}\")\n",
        "print(f\"  But this is just the Level component - spreads adjust from this base\")\n",
        "print(f\"Front: MC_to_total={MC_front_check:.2f}, recon_error={recon_error_front:.2e}\")\n",
        "\n",
        "# Mid bucket\n",
        "B_mid, factor_names_mid, _ = build_factor_matrix_bucket(mid, 'mid')\n",
        "factor_detail_mid, MC_mid_check, recon_error_mid = compute_factor_risk_metrics(\n",
        "    w_mid, Sigma_mid, B_mid, factor_names_mid,\n",
        "    Sigma_total, w_total, n_front, n_total\n",
        ")\n",
        "factor_detail_mid.insert(0, 'bucket', 'Mid')\n",
        "print(f\"Mid: MC_to_total={MC_mid_check:.2f}, recon_error={recon_error_mid:.2e}\")\n",
        "\n",
        "# Back bucket\n",
        "B_back, factor_names_back, residual_name = build_factor_matrix_bucket(back, 'back')\n",
        "factor_detail_back, MC_back_check, recon_error_back = compute_factor_risk_metrics(\n",
        "    w_back, Sigma_back, B_back, factor_names_back,\n",
        "    Sigma_total, w_total, n_front + n_mid, n_total, residual_name\n",
        ")\n",
        "factor_detail_back.insert(0, 'bucket', 'Back')\n",
        "print(f\"Back: MC_to_total={MC_back_check:.2f}, recon_error={recon_error_back:.2e}\")\n",
        "\n",
        "# Combine all buckets\n",
        "factor_detail_df = pd.concat([factor_detail_front, factor_detail_mid, factor_detail_back], ignore_index=True)\n",
        "\n",
        "print(\"\\nFactor Detail DataFrame:\")\n",
        "print(factor_detail_df.to_string(index=False))\n",
        "\n",
        "# Explanation about factor MCs using full covariance\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FACTOR MCs USE FULL COVARIANCE MATRIX\")\n",
        "print(\"=\"*80)\n",
        "print(\"Factor MCs in factor_detail_df are computed using the FULL covariance matrix (Î£_total):\")\n",
        "front_level_mc = factor_detail_df[(factor_detail_df['bucket'] == 'Front') & (factor_detail_df['factor_name'] == 'Level')]['MC_$per_day'].values[0]\n",
        "mid_level_mc = factor_detail_df[(factor_detail_df['bucket'] == 'Mid') & (factor_detail_df['factor_name'] == 'Level')]['MC_$per_day'].values[0]\n",
        "front_mc_to_total = bucket_summary_df[bucket_summary_df['bucket'] == 'Front']['MC_to_total'].values[0]\n",
        "mid_mc_to_total = bucket_summary_df[bucket_summary_df['bucket'] == 'Mid']['MC_to_total'].values[0]\n",
        "total_q = bucket_summary_df[bucket_summary_df['bucket'] == 'TOTAL']['standalone_Q'].values[0]\n",
        "\n",
        "print(f\"  Front Level MC (contribution to total portfolio): {front_level_mc:.2f}\")\n",
        "print(f\"  Mid Level MC (contribution to total portfolio): {mid_level_mc:.2f}\")\n",
        "print(f\"  Sum of Level MCs: {front_level_mc + mid_level_mc:.2f}\")\n",
        "print(f\"\\n  Front bucket MC_to_total: {front_mc_to_total:.2f}\")\n",
        "print(f\"  Mid bucket MC_to_total: {mid_mc_to_total:.2f}\")\n",
        "print(f\"  Sum of bucket MCs: {front_mc_to_total + mid_mc_to_total:.2f}\")\n",
        "print(f\"  Total Q: {total_q:.2f}\")\n",
        "print(f\"\\n  Key insight:\")\n",
        "print(\"  - Factor MCs show contribution to TOTAL portfolio risk (using Î£_total)\")\n",
        "print(\"  - Factor MCs within each bucket sum to that bucket's MC_to_total\")\n",
        "print(\"  - This accounts for cross-bucket correlations and diversification effects\")\n",
        "print(\"  - Sum of all factor MCs across all buckets = Total Q\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FACTOR DECOMPOSITION EXPLANATION:\")\n",
        "print(\"=\"*80)\n",
        "print(\"For Front/Mid buckets, factors are: Level + adjacent spreads\")\n",
        "print(\"\\nLevel Factor:\")\n",
        "print(\"  - Level factor vector: [1/n, 1/n, ..., 1/n] = [0.25, 0.25, 0.25, 0.25] for Front\")\n",
        "print(\"  - Level exposure (qty_lots) = TOTAL NET POSITION across all nodes\")\n",
        "print(\"  - Mathematical relationship:\")\n",
        "print(\"    * Level contributes (1/n) * e_level to each node\")\n",
        "print(\"    * Sum of all positions = n * (1/n) * e_level = e_level\")\n",
        "print(\"    * Therefore: Level exposure = sum(positions)\")\n",
        "print(\"\\n  Example:\")\n",
        "print(f\"    * Node positions: {w_front}\")\n",
        "print(f\"    * Total net position: {w_front.sum()}\")\n",
        "print(f\"    * Level exposure: {w_front.sum()} (NOT the average!)\")\n",
        "print(f\"    * Level contributes {0.25 * w_front.sum():.0f} to each node (before spreads)\")\n",
        "print(\"\\nSpread Factors:\")\n",
        "print(\"  - Each spread (e.g., A01/A02) represents the difference between adjacent nodes\")\n",
        "print(\"  - Spread exposures adjust positions from the Level base\")\n",
        "print(\"  - Final position = Level contribution + spread adjustments\")\n",
        "print(\"\\n  Example reconstruction:\")\n",
        "print(f\"    * A01 final = {w_front[0]}\")\n",
        "print(f\"    * A01 = Level_base + spread_adjustments\")\n",
        "print(f\"    * Level_base = (1/4) * {w_front.sum()} = {0.25 * w_front.sum():.0f}\")\n",
        "print(f\"    * Spread adjustments = {w_front[0] - 0.25 * w_front.sum():.0f}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Tie-out assertions - factor MCs should sum to bucket MC_to_total\n",
        "for bucket_name, MC_check, MC_actual in [('Front', MC_front_check, MC_front), \n",
        "                                         ('Mid', MC_mid_check, MC_mid), \n",
        "                                         ('Back', MC_back_check, MC_back)]:\n",
        "    if abs(MC_actual) > 1e-10:\n",
        "        rel_error = abs(MC_check - MC_actual) / abs(MC_actual)\n",
        "        assert rel_error < 1e-3, f\"{bucket_name} MC_to_total tie-out failed: {rel_error:.6f}\"\n",
        "        print(f\"\\nâœ“ {bucket_name} MC_to_total tie-out (computed vs bucket_summary): {MC_check:.2f} vs {MC_actual:.2f} (error: {rel_error:.6f})\")\n",
        "    elif abs(MC_check) < 1e-6 and abs(MC_actual) < 1e-6:\n",
        "        print(f\"\\nâœ“ {bucket_name} MC_to_total tie-out: both zero (no positions)\")\n",
        "\n",
        "# Check factor MC sums - should equal bucket MC_to_total\n",
        "for bucket_name, MC_target in [('Front', MC_front_check), ('Mid', MC_mid_check), ('Back', MC_back_check)]:\n",
        "    bucket_factors = factor_detail_df[factor_detail_df['bucket'] == bucket_name]\n",
        "    mc_sum = bucket_factors['MC_$per_day'].sum()\n",
        "    if abs(MC_target) > 1e-10:  # Use small threshold to avoid division by zero\n",
        "        rel_error = abs(mc_sum - MC_target) / abs(MC_target)\n",
        "        assert rel_error < 1e-3, f\"{bucket_name} factor MC sum tie-out failed: {rel_error:.6f}\"\n",
        "        print(f\"âœ“ {bucket_name} factor MC sum tie-out: {mc_sum:.2f} vs {MC_target:.2f} (error: {rel_error:.6f})\")\n",
        "    elif abs(mc_sum) < 1e-6 and abs(MC_target) < 1e-6:\n",
        "        # Both are effectively zero - this is correct\n",
        "        print(f\"âœ“ {bucket_name} factor MC sum tie-out: both zero (no positions)\")\n",
        "    else:\n",
        "        # One is zero but the other isn't - this is an error\n",
        "        abs_error = abs(mc_sum - MC_target)\n",
        "        assert abs_error < 1e-6, f\"{bucket_name} factor MC sum tie-out failed: MC_sum={mc_sum:.2f}, MC_target={MC_target:.2f}, abs_error={abs_error:.6f}\"\n",
        "        print(f\"âœ“ {bucket_name} factor MC sum tie-out: {mc_sum:.2f} vs {MC_target:.2f} (both effectively zero)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Level vs Structure DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Level vs Structure DataFrame:\n",
            "bucket         Level    Structure   MC_to_total  Level_pct  Structure_pct\n",
            " Front 130206.517630 2.689180e-09 130206.517630 100.000000   2.065319e-12\n",
            "   Mid  60412.225362 7.739476e-05  60412.225439 100.000000   1.281111e-07\n",
            "  Back    740.634939 6.549797e-02    740.700437  99.991157   8.842708e-03\n",
            "\n",
            "Note: Level and Structure MCs sum to bucket MC_to_total (contribution to total portfolio risk)\n",
            "\n",
            "âœ“ Front Level+Structure tie-out: 130206.52 vs 130206.52 (error: 0.000000)\n",
            "\n",
            "âœ“ Mid Level+Structure tie-out: 60412.23 vs 60412.23 (error: 0.000000)\n",
            "\n",
            "âœ“ Back Level+Structure tie-out: 740.70 vs 740.70 (error: 0.000000)\n"
          ]
        }
      ],
      "source": [
        "# Aggregate factor_detail_df into Level vs Structure per bucket\n",
        "# Note: Factor MCs now use full covariance, so they sum to bucket MC_to_total (not standalone Q)\n",
        "level_structure_rows = []\n",
        "\n",
        "for bucket_name in ['Front', 'Mid', 'Back']:\n",
        "    bucket_factors = factor_detail_df[factor_detail_df['bucket'] == bucket_name].copy()\n",
        "    \n",
        "    # Level contribution\n",
        "    level_row = bucket_factors[bucket_factors['factor_name'] == 'Level'].iloc[0]\n",
        "    level_MC = level_row['MC_$per_day']\n",
        "    \n",
        "    # Structure contribution = sum of all spreads + residual\n",
        "    structure_factors = bucket_factors[bucket_factors['factor_name'] != 'Level']\n",
        "    structure_MC = structure_factors['MC_$per_day'].sum()\n",
        "    \n",
        "    # Bucket MC_to_total (should equal Level + Structure)\n",
        "    bucket_MC = bucket_summary_df[bucket_summary_df['bucket'] == bucket_name]['MC_to_total'].values[0]\n",
        "    \n",
        "    level_structure_rows.append({\n",
        "        'bucket': bucket_name,\n",
        "        'Level': level_MC,\n",
        "        'Structure': structure_MC,\n",
        "        'MC_to_total': bucket_MC,\n",
        "        'Level_pct': 100 * level_MC / bucket_MC if abs(bucket_MC) > 1e-10 else 0,\n",
        "        'Structure_pct': 100 * structure_MC / bucket_MC if abs(bucket_MC) > 1e-10 else 0\n",
        "    })\n",
        "\n",
        "level_structure_df = pd.DataFrame(level_structure_rows)\n",
        "\n",
        "print(\"Level vs Structure DataFrame:\")\n",
        "print(level_structure_df.to_string(index=False))\n",
        "print(\"\\nNote: Level and Structure MCs sum to bucket MC_to_total (contribution to total portfolio risk)\")\n",
        "\n",
        "# Verify Level + Structure = MC_to_total\n",
        "for _, row in level_structure_df.iterrows():\n",
        "    total_check = row['Level'] + row['Structure']\n",
        "    mc_target = row['MC_to_total']\n",
        "    if abs(mc_target) > 1e-10:\n",
        "        rel_error = abs(total_check - mc_target) / abs(mc_target)\n",
        "        assert rel_error < 1e-3, f\"{row['bucket']} Level+Structure tie-out failed: {rel_error:.6f}\"\n",
        "        print(f\"\\nâœ“ {row['bucket']} Level+Structure tie-out: {total_check:.2f} vs {mc_target:.2f} (error: {rel_error:.6f})\")\n",
        "    elif abs(total_check) < 1e-6 and abs(mc_target) < 1e-6:\n",
        "        print(f\"\\nâœ“ {row['bucket']} Level+Structure tie-out: both zero\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Top Drivers + Skew Direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top Drivers + Skew Direction:\n",
            "(All values use FULL covariance matrix - MC shows contribution to TOTAL portfolio risk)\n",
            "bucket top_factor_by_abs_MC  factor_qty  factor_slope     factor_MC AS_direction\n",
            " Front                Level     -4674.0     -5.330819 130206.517630          BUY\n",
            "   Mid                Level      4600.0      2.513141  60412.225362         SELL\n",
            "  Back                Level      -675.0     -0.209967    740.634939          BUY\n"
          ]
        }
      ],
      "source": [
        "# Extract top factor by absolute MC for each bucket\n",
        "# Note: MC_$per_day values come from factor_detail_df, which uses FULL covariance matrix (Î£_total)\n",
        "# These are marginal contributions to TOTAL portfolio risk, not standalone bucket Q\n",
        "top_drivers_rows = []\n",
        "\n",
        "for bucket_name in ['Front', 'Mid', 'Back']:\n",
        "    bucket_factors = factor_detail_df[factor_detail_df['bucket'] == bucket_name].copy()\n",
        "    \n",
        "    # Find factor with maximum absolute MC (marginal contribution to total portfolio)\n",
        "    # MC_$per_day is computed using: MC = 1000 * (exposure * slope) / sqrt(w_total' Î£_total w_total)\n",
        "    # where slope = B_full' @ Î£_total @ w_total (marginal contribution to total portfolio risk)\n",
        "    bucket_factors['abs_MC'] = bucket_factors['MC_$per_day'].abs()\n",
        "    top_factor = bucket_factors.loc[bucket_factors['abs_MC'].idxmax()]\n",
        "    \n",
        "    top_drivers_rows.append({\n",
        "        'bucket': bucket_name,\n",
        "        'top_factor_by_abs_MC': top_factor['factor_name'],\n",
        "        'factor_qty': top_factor['qty_lots'],\n",
        "        'factor_slope': top_factor['marginal_slope'],  # Slope using full covariance: B_full' @ Î£_total @ w_total\n",
        "        'factor_MC': top_factor['MC_$per_day'],  # MC to total portfolio using full covariance\n",
        "        'AS_direction': top_factor['AS_skew_direction']\n",
        "    })\n",
        "\n",
        "top_drivers_df = pd.DataFrame(top_drivers_rows)\n",
        "\n",
        "print(\"Top Drivers + Skew Direction:\")\n",
        "print(\"(All values use FULL covariance matrix - MC shows contribution to TOTAL portfolio risk)\")\n",
        "print(top_drivers_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Hedge Recommender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hedge Recommender Example:\n",
            "Example 1: Target spread A03/A04, q_target_lots = 1000\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Hedge Summary for Spread A03/A04 (sorted by variance reduction):\n",
            "hedge_instrument      corr      beta  var_reduction  recommended_hedge_lots_for_q_target\n",
            "         A03/A04  1.000000  1.000000       1.000000                         -1000.000000\n",
            "             A03  0.512566  0.393944       0.262724                          -393.943531\n",
            "             A02  0.468688  0.283847       0.219669                          -283.847468\n",
            "             A01  0.368025  0.197833       0.135443                          -197.833325\n",
            "             A04 -0.285721 -0.245086       0.081637                           245.086455\n",
            "         A02/A03  0.105432  0.103896       0.011116                          -103.896059\n",
            "         A01/A02 -0.074044 -0.061417       0.005483                            61.417226\n",
            "\n",
            "\n",
            "Example 2: Target outright A01, q_target_lots = 1000\n",
            "================================================================================\n",
            "\n",
            "Hedge Summary for Outright A01 (sorted by variance reduction):\n",
            "hedge_instrument     corr     beta  var_reduction  recommended_hedge_lots_for_q_target\n",
            "             A01 1.000000 1.000000       1.000000                         -1000.000000\n",
            "             A02 0.770528 0.868095       0.593713                          -868.095183\n",
            "             A03 0.639598 0.914471       0.409086                          -914.471356\n",
            "         A01/A02 0.487716 0.752567       0.237867                          -752.566658\n",
            "         A02/A03 0.433691 0.795033       0.188088                          -795.033227\n",
            "             A04 0.398152 0.635337       0.158525                          -635.336720\n",
            "         A03/A04 0.368025 0.684630       0.135443                          -684.630323\n"
          ]
        }
      ],
      "source": [
        "def determine_bucket_for_instrument(instrument_name, front_nodes, mid_nodes, back_nodes):\n",
        "    \"\"\"\n",
        "    Determine which bucket an instrument (spread or outright) belongs to.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    instrument_name : str\n",
        "        Instrument name, either a spread (e.g., \"A03/A04\") or an outright (e.g., \"A01\")\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (bucket_type, bucket_nodes) or None if cannot determine\n",
        "    \"\"\"\n",
        "    # Check if it's a spread (contains '/')\n",
        "    if '/' in instrument_name:\n",
        "        # Parse spread (e.g., \"A03/A04\")\n",
        "        parts = instrument_name.split('/')\n",
        "        if len(parts) != 2:\n",
        "            return None\n",
        "        \n",
        "        node1, node2 = parts[0], parts[1]\n",
        "        \n",
        "        # Check if both nodes are in the same bucket\n",
        "        if node1 in front_nodes and node2 in front_nodes:\n",
        "            return 'front', front_nodes\n",
        "        elif node1 in mid_nodes and node2 in mid_nodes:\n",
        "            return 'mid', mid_nodes\n",
        "        elif node1 in back_nodes and node2 in back_nodes:\n",
        "            return 'back', back_nodes\n",
        "        \n",
        "        # If spread spans buckets, determine primary bucket\n",
        "        if node1 in front_nodes or node2 in front_nodes:\n",
        "            return 'front', front_nodes\n",
        "        elif node1 in mid_nodes or node2 in mid_nodes:\n",
        "            return 'mid', mid_nodes\n",
        "        else:\n",
        "            return 'back', back_nodes\n",
        "    else:\n",
        "        # It's an outright (e.g., \"A01\")\n",
        "        node = instrument_name\n",
        "        \n",
        "        # Determine which bucket the node belongs to\n",
        "        if node in front_nodes:\n",
        "            return 'front', front_nodes\n",
        "        elif node in mid_nodes:\n",
        "            return 'mid', mid_nodes\n",
        "        elif node in back_nodes:\n",
        "            return 'back', back_nodes\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "def build_hedge_universe(bucket_nodes, bucket_type, returns_df, product):\n",
        "    \"\"\"Build hedge universe for a bucket.\"\"\"\n",
        "    hedge_instruments = []\n",
        "    \n",
        "    # Outrights in bucket\n",
        "    for node in bucket_nodes:\n",
        "        hedge_instruments.append(node)\n",
        "    \n",
        "    # Adjacent spreads\n",
        "    for i in range(len(bucket_nodes) - 1):\n",
        "        spread_name = f\"{bucket_nodes[i]}/{bucket_nodes[i+1]}\"\n",
        "        hedge_instruments.append(spread_name)\n",
        "    \n",
        "    # For back bucket, add longer/coarse spreads\n",
        "    if bucket_type == 'back':\n",
        "        # Add some longer spreads\n",
        "        if len(bucket_nodes) >= 4:\n",
        "            hedge_instruments.append(f\"{bucket_nodes[0]}/{bucket_nodes[3]}\")  # A09/A12\n",
        "        if len(bucket_nodes) >= 6:\n",
        "            hedge_instruments.append(f\"{bucket_nodes[2]}/{bucket_nodes[5]}\")  # A11/A14\n",
        "    \n",
        "    return hedge_instruments\n",
        "\n",
        "def compute_instrument_returns(returns_df, instrument_name, bucket_nodes, product):\n",
        "    \"\"\"Compute returns for an instrument (outright or spread).\"\"\"\n",
        "    if '/' not in instrument_name:\n",
        "        # Outright\n",
        "        col = f\"{product}_{instrument_name}\"\n",
        "        if col in returns_df.columns:\n",
        "            return returns_df[col].values\n",
        "        else:\n",
        "            return None\n",
        "    else:\n",
        "        # Spread\n",
        "        parts = instrument_name.split('/')\n",
        "        node1, node2 = parts[0], parts[1]\n",
        "        col1 = f\"{product}_{node1}\"\n",
        "        col2 = f\"{product}_{node2}\"\n",
        "        \n",
        "        if col1 in returns_df.columns and col2 in returns_df.columns:\n",
        "            return returns_df[col1].values - returns_df[col2].values\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "def compute_ewma_variance(returns_series, lambda_val, init_obs=60):\n",
        "    \"\"\"Compute EWMA variance for a single series.\"\"\"\n",
        "    returns_array = returns_series[~np.isnan(returns_series)]\n",
        "    n_obs = len(returns_array)\n",
        "    \n",
        "    if n_obs < init_obs:\n",
        "        return np.var(returns_array) if n_obs > 1 else 0.0\n",
        "    \n",
        "    # Initialize with sample variance\n",
        "    var_current = np.var(returns_array[:init_obs])\n",
        "    \n",
        "    # EWMA recursion\n",
        "    for t in range(init_obs, n_obs):\n",
        "        r_t = returns_array[t]\n",
        "        if not np.isnan(r_t):\n",
        "            var_current = lambda_val * var_current + (1 - lambda_val) * r_t**2\n",
        "    \n",
        "    return var_current\n",
        "\n",
        "def compute_ewma_covariance_pair(returns1, returns2, lambda_val, init_obs=60):\n",
        "    \"\"\"Compute EWMA covariance between two series.\"\"\"\n",
        "    # Align series\n",
        "    valid_mask = ~(np.isnan(returns1) | np.isnan(returns2))\n",
        "    r1 = returns1[valid_mask]\n",
        "    r2 = returns2[valid_mask]\n",
        "    \n",
        "    n_obs = len(r1)\n",
        "    \n",
        "    if n_obs < init_obs:\n",
        "        return np.cov(r1[:init_obs], r2[:init_obs])[0, 1] if n_obs > 1 else 0.0\n",
        "    \n",
        "    # Initialize with sample covariance\n",
        "    cov_current = np.cov(r1[:init_obs], r2[:init_obs])[0, 1]\n",
        "    \n",
        "    # EWMA recursion\n",
        "    for t in range(init_obs, n_obs):\n",
        "        r1_t = r1[t]\n",
        "        r2_t = r2[t]\n",
        "        if not (np.isnan(r1_t) or np.isnan(r2_t)):\n",
        "            cov_current = lambda_val * cov_current + (1 - lambda_val) * r1_t * r2_t\n",
        "    \n",
        "    return cov_current\n",
        "\n",
        "def recommend_hedge(target_instrument, q_target_lots, product, returns_df, \n",
        "                    front_nodes, mid_nodes, back_nodes,\n",
        "                    lambda_front, lambda_mid, lambda_back):\n",
        "    \"\"\"\n",
        "    Recommend hedge for a target instrument (spread or outright).\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    target_instrument : str\n",
        "        Target instrument, either a spread (e.g., \"A03/A04\") or an outright (e.g., \"A01\")\n",
        "    q_target_lots : float\n",
        "        Target position size in lots\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    hedge_summary_df : DataFrame sorted by var_reduction desc\n",
        "    \"\"\"\n",
        "    # Determine bucket\n",
        "    bucket_info = determine_bucket_for_instrument(target_instrument, front_nodes, mid_nodes, back_nodes)\n",
        "    if bucket_info is None:\n",
        "        raise ValueError(f\"Cannot determine bucket for instrument {target_instrument}\")\n",
        "    \n",
        "    bucket_type, bucket_nodes = bucket_info\n",
        "    \n",
        "    # Get lambda for this bucket\n",
        "    lambda_map = {'front': lambda_front, 'mid': lambda_mid, 'back': lambda_back}\n",
        "    lambda_val = lambda_map[bucket_type]\n",
        "    \n",
        "    # Build hedge universe\n",
        "    hedge_universe = build_hedge_universe(bucket_nodes, bucket_type, returns_df, product)\n",
        "    \n",
        "    # Compute target returns\n",
        "    target_returns = compute_instrument_returns(returns_df, target_instrument, bucket_nodes, product)\n",
        "    if target_returns is None:\n",
        "        raise ValueError(f\"Cannot compute returns for target {target_instrument}\")\n",
        "    \n",
        "    # Compute EWMA covariance for target\n",
        "    target_var = compute_ewma_variance(target_returns, lambda_val, ewma_init_obs)\n",
        "    \n",
        "    # Evaluate each hedge instrument\n",
        "    hedge_results = []\n",
        "    \n",
        "    for hedge_instrument in hedge_universe:\n",
        "        hedge_returns = compute_instrument_returns(returns_df, hedge_instrument, bucket_nodes, product)\n",
        "        if hedge_returns is None:\n",
        "            continue\n",
        "        \n",
        "        # Compute covariance between target and hedge\n",
        "        cov_target_hedge = compute_ewma_covariance_pair(target_returns, hedge_returns, lambda_val, ewma_init_obs)\n",
        "        hedge_var = compute_ewma_variance(hedge_returns, lambda_val, ewma_init_obs)\n",
        "        \n",
        "        if hedge_var <= 0:\n",
        "            continue\n",
        "        \n",
        "        # Hedge ratio: beta = Cov(T,H) / Var(H)\n",
        "        beta = cov_target_hedge / hedge_var\n",
        "        \n",
        "        # Variance reduction: 1 - Var(T - beta*H) / Var(T)\n",
        "        if target_var > 0:\n",
        "            hedged_var = target_var - 2 * beta * cov_target_hedge + beta**2 * hedge_var\n",
        "            var_reduction = 1 - hedged_var / target_var\n",
        "        else:\n",
        "            var_reduction = 0.0\n",
        "        \n",
        "        # Correlation: Corr = Cov / (sqrt(VarT * VarH))\n",
        "        if target_var > 0 and hedge_var > 0:\n",
        "            corr = cov_target_hedge / np.sqrt(target_var * hedge_var)\n",
        "        else:\n",
        "            corr = 0.0\n",
        "        \n",
        "        # Recommended hedge lots: x = -q_target_lots * beta\n",
        "        recommended_hedge_lots = -q_target_lots * beta\n",
        "        \n",
        "        hedge_results.append({\n",
        "            'hedge_instrument': hedge_instrument,\n",
        "            'corr': corr,\n",
        "            'beta': beta,\n",
        "            'var_reduction': var_reduction,\n",
        "            'recommended_hedge_lots_for_q_target': recommended_hedge_lots\n",
        "        })\n",
        "    \n",
        "    hedge_summary_df = pd.DataFrame(hedge_results)\n",
        "    hedge_summary_df = hedge_summary_df.sort_values('var_reduction', ascending=False)\n",
        "    \n",
        "    return hedge_summary_df\n",
        "\n",
        "# Example: Recommend hedge for a spread or outright\n",
        "print(\"Hedge Recommender Example:\")\n",
        "print(\"Example 1: Target spread A03/A04, q_target_lots = 1000\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "hedge_summary_spread = recommend_hedge(\n",
        "    target_instrument=\"A03/A04\",\n",
        "    q_target_lots=1000,\n",
        "    product=product,\n",
        "    returns_df=df_returns,\n",
        "    front_nodes=front,\n",
        "    mid_nodes=mid,\n",
        "    back_nodes=back,\n",
        "    lambda_front=lambda_front,\n",
        "    lambda_mid=lambda_mid,\n",
        "    lambda_back=lambda_back\n",
        ")\n",
        "\n",
        "print(\"\\nHedge Summary for Spread A03/A04 (sorted by variance reduction):\")\n",
        "print(hedge_summary_spread.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\nExample 2: Target outright A01, q_target_lots = 1000\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "hedge_summary_outright = recommend_hedge(\n",
        "    target_instrument=\"A01\",\n",
        "    q_target_lots=1000,\n",
        "    product=product,\n",
        "    returns_df=df_returns,\n",
        "    front_nodes=front,\n",
        "    mid_nodes=mid,\n",
        "    back_nodes=back,\n",
        "    lambda_front=lambda_front,\n",
        "    lambda_mid=lambda_mid,\n",
        "    lambda_back=lambda_back\n",
        ")\n",
        "\n",
        "print(\"\\nHedge Summary for Outright A01 (sorted by variance reduction):\")\n",
        "print(hedge_summary_outright.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Final Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Q RISK REPORT SUMMARY\n",
            "================================================================================\n",
            "\n",
            "1. BUCKET SUMMARY:\n",
            "bucket  standalone_Q   MC_to_total Q_check MC_signed\n",
            " Front 146968.676584 130302.608258      OK       POS\n",
            "   Mid  76672.690085  35463.773442      OK       POS\n",
            "  Back      0.000000      0.000000      OK      ZERO\n",
            " TOTAL 165766.381700           NaN      OK      ZERO\n",
            "\n",
            "\n",
            "2. LEVEL VS STRUCTURE:\n",
            "bucket         Level    Structure   MC_to_total  Level_pct  Structure_pct\n",
            " Front 130302.608258 5.964779e-08 130302.608258      100.0   4.577636e-11\n",
            "   Mid  35463.773346 9.638538e-05  35463.773442      100.0   2.717855e-07\n",
            "  Back      0.000000 1.657664e+05      0.000000        0.0   0.000000e+00\n",
            "\n",
            "\n",
            "3. TOP DRIVERS:\n",
            "bucket top_factor_by_abs_MC  factor_qty  factor_slope     factor_MC AS_direction\n",
            " Front                Level      3000.0      7.199931 130302.608258         SELL\n",
            "   Mid                Level     -3000.0     -1.959567  35463.773346          BUY\n",
            "  Back                Level         0.0      0.000000      0.000000      NEUTRAL\n",
            "\n",
            "\n",
            "4. FACTOR DETAIL (first 20 rows):\n",
            "bucket   factor_name  qty_lots  marginal_slope  MC_$per_day  pct_of_bucket_Q AS_skew_direction\n",
            " Front         Level    3000.0    7.199931e+00 1.303026e+05     1.000000e+02              SELL\n",
            " Front       A01/A02     750.0    1.744861e-12 7.894517e-09     6.058603e-12              SELL\n",
            " Front       A02/A03    1500.0    2.036457e-12 1.842765e-08     1.414220e-11              SELL\n",
            " Front       A03/A04    2250.0    2.455230e-12 3.332562e-08     2.557556e-11              SELL\n",
            "   Mid         Level   -3000.0   -1.959567e+00 3.546377e+04     1.000000e+02               BUY\n",
            "   Mid       A05/A06    -750.0   -2.118808e-09 9.586417e-06     2.703158e-08               BUY\n",
            "   Mid       A06/A07   -1500.0   -5.887046e-09 5.327117e-05     1.502129e-07               BUY\n",
            "   Mid       A07/A08    -750.0   -7.410376e-09 3.352780e-05     9.454098e-08               BUY\n",
            "  Back         Level       0.0    0.000000e+00 0.000000e+00     0.000000e+00           NEUTRAL\n",
            "  Back Block1-Block2       0.0    0.000000e+00 0.000000e+00     0.000000e+00           NEUTRAL\n",
            "  Back Block2-Block3       0.0    0.000000e+00 0.000000e+00     0.000000e+00           NEUTRAL\n",
            "  Back    Early-Late       0.0    0.000000e+00 0.000000e+00     0.000000e+00           NEUTRAL\n",
            "  Back       A09/A12       0.0    0.000000e+00 0.000000e+00     0.000000e+00           NEUTRAL\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Report generation complete.\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"Q RISK REPORT SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1. BUCKET SUMMARY:\")\n",
        "print(bucket_summary_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\n2. LEVEL VS STRUCTURE:\")\n",
        "print(level_structure_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\n3. TOP DRIVERS:\")\n",
        "print(top_drivers_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\\n4. FACTOR DETAIL (first 20 rows):\")\n",
        "print(factor_detail_df.head(20).to_string(index=False))\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*80)\n",
        "print(\"Report generation complete.\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
